{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a3913e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.dev2313\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 2.0.0+cu118\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 331437dfce075b4fa5785016ad4e7f8c7c77ad21\n",
      "MONAI __file__: D:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: 5.3.0\n",
      "Nibabel version: 5.0.1\n",
      "scikit-image version: 0.20.0\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.12.0\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.15.1+cu118\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: 1.4.0\n",
      "psutil version: 5.9.4\n",
      "pandas version: 1.5.3\n",
      "einops version: 0.6.0\n",
      "transformers version: 4.27.3\n",
      "mlflow version: 2.2.2\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from trainer import Trainer\n",
    "\n",
    "from Preprocessing import (\n",
    "    filter_collate_fn,\n",
    "    generate_file_path,\n",
    "    get_train_transform,\n",
    "    get_validation_transform\n",
    ")\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    ThreadDataLoader,\n",
    "    SmartCacheDataset,\n",
    "    PersistentDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    "    set_track_meta,\n",
    ")\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from map_to_binary import class_map_5_parts\n",
    "from monai.data.utils import pad_list_data_collate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc77eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'ribs'\n",
    "val_transforms = get_validation_transform()\n",
    "train_transforms = get_train_transform(num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413decb",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9d9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dataset = 'DatasetCombined'\n",
    "label_name = f'labels_task_{task_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f55386",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_val = generate_file_path(root_path=f'{root_dataset}/val', label_name=label_name)\n",
    "file_list_train = generate_file_path(root_path=f'{root_dataset}/train', label_name=label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95cfe5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PersistentDataset(\n",
    "    data=file_list_train,\n",
    "    transform=train_transforms,\n",
    "    cache_dir=f'C:/Training/train_{task_name}'\n",
    ")\n",
    "\n",
    "train_loader = ThreadDataLoader(train_ds, batch_size=1, shuffle=True,\n",
    "                                collate_fn=lambda x: pad_list_data_collate(x, pad_to_shape=(96, 96, 96))\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848ee03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = PersistentDataset(\n",
    "    data=file_list_val,\n",
    "    transform=val_transforms,\n",
    "    cache_dir=f'val_{task_name}'\n",
    "#     cache_dir='C:/Training/val'\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=0,\n",
    "                              collate_fn=lambda x: pad_list_data_collate(x, pad_to_shape=(96, 96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0492cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes = len(class_map_5_parts[f'class_map_part_{task_name}']) + 1\n",
    "num_of_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8360d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88096e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'Model'\n",
    "model_folder = os.path.join(root_dir, f'SwinTransformer_{task_name}')\n",
    "if not os.path.isdir(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a65e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=num_of_classes,\n",
    "    feature_size=48,\n",
    "#     drop_rate=0.25,\n",
    "    use_checkpoint=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7abd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True, lambda_dice=1, lambda_ce=1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39db20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_trainer = Trainer(\n",
    "    model=model,\n",
    "    max_epoch=1000,\n",
    "    optimizer=optimizer,\n",
    "    num_samples=4,\n",
    "    loss_function=loss_function,\n",
    "    model_root_path=model_folder,\n",
    "    number_of_classes=num_of_classes,\n",
    "    )\n",
    "swin_trainer.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04730486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training (X / X Steps) (loss=X.X):   0%|                                                      | 0/1081 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(4.7374, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=4.73743):   0%|                                     | 1/1081 [00:10<3:01:31, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(4.5330, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=4.53298):   0%|                                     | 2/1081 [00:10<1:23:18,  4.63s/it]Num foregrounds 0, Num backgrounds 1975669, unable to generate class balanced samples, setting `pos_ratio` to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(4.3436, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=4.34364):   0%|                                       | 3/1081 [00:11<50:23,  2.81s/it]Num foregrounds 0, Num backgrounds 2582709, unable to generate class balanced samples, setting `pos_ratio` to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(4.2770, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=4.27696):   0%|▏                                      | 4/1081 [00:12<34:57,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(4.1567, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=4.15671):   1%|▎                                      | 7/1081 [00:13<16:09,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(4.0244, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=4.02439):   1%|▎                                      | 8/1081 [00:13<15:12,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(4.2272, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=4.22721):   1%|▎                                      | 9/1081 [00:14<14:12,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(3.9478, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=3.94779):   1%|▎                                     | 10/1081 [00:14<13:28,  1.33it/s]Num foregrounds 0, Num backgrounds 3609327, unable to generate class balanced samples, setting `pos_ratio` to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(3.8630, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=3.86303):   1%|▍                                     | 11/1081 [00:15<12:51,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(3.9375, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (0 / 1000 Steps) (loss=3.86303):   1%|▍                                     | 11/1081 [00:16<25:58,  1.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mswin_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Arash\\AnatomySegmentation\\trainer.py:172\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# dice_val_best = 0.0\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# global_step_best = 0\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# epoch_loss_values = []\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# metric_values = []\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# val_loss_values = []\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m global_step \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epoch:\n\u001b[1;32m--> 172\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Free GPU memory\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32mD:\\Arash\\AnatomySegmentation\\trainer.py:136\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch\u001b[1;34m(self, train_loader, global_step)\u001b[0m\n\u001b[0;32m    134\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(logit_map, y)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss):\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\_tensor.py:478\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\overrides.py:1551\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1545\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1546\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1547\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[1;32m-> 1551\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\data\\meta_tensor.py:276\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 276\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "swin_trainer.train(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb527c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7926767468452454 38\n"
     ]
    }
   ],
   "source": [
    "# swin_trainer.continue_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48463085",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_test = generate_file_path(root_path=f'{root_dataset}/test', label_name=label_name)\n",
    "test_ds = PersistentDataset(\n",
    "    data=file_list_test,\n",
    "    transform=val_transforms,\n",
    "    cache_dir=f'test_{task_name}'\n",
    "#     cache_dir='C:/Training/val'\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_ds, num_workers=0, batch_size=1, \n",
    "                              collate_fn=lambda x: pad_list_data_collate(x, pad_to_shape=(96, 96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f58896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|                                                                                     | 0/59 [00:00<?, ?it/s]None of the inputs have requires_grad=True. Gradients will be None\n",
      "invalid value encountered in double_scalars\n",
      "torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "Test (loss=0.42146): 100%|█████████████████████████████████████████████████████████████| 59/59 [15:20<00:00, 15.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.895768834475794,\n",
       "  0.9201364163609356,\n",
       "  0.8860244164216201,\n",
       "  0.8946778937836815,\n",
       "  0.8392086691770765,\n",
       "  0.8177011791745522,\n",
       "  0.8418752117262379,\n",
       "  0.7761074226873641,\n",
       "  0.8100964495235019,\n",
       "  0.8244390337758317,\n",
       "  0.8728070978232708,\n",
       "  0.9111084391081988,\n",
       "  0.9112752588282829,\n",
       "  0.9435089411592043,\n",
       "  0.911306074623276,\n",
       "  0.8385566770126578,\n",
       "  0.792008334060771,\n",
       "  0.7786670859170043,\n",
       "  0.7955097125955667,\n",
       "  0.7963218980480847,\n",
       "  0.8099165194143754,\n",
       "  0.8194729435963692,\n",
       "  0.83535694010435,\n",
       "  0.8760811499505977],\n",
       " [13.295742517532162,\n",
       "  13.287056361847812,\n",
       "  18.137136281267434,\n",
       "  15.62910553601502,\n",
       "  19.47151678960597,\n",
       "  17.445150418608655,\n",
       "  18.232191544636777,\n",
       "  22.82304378002099,\n",
       "  20.43339424720071,\n",
       "  22.323808389604803,\n",
       "  20.460160764781023,\n",
       "  7.388015448552459,\n",
       "  8.657086733270763,\n",
       "  4.890540851659967,\n",
       "  10.27575774355458,\n",
       "  20.831213899995447,\n",
       "  21.65831466475856,\n",
       "  23.578638529506,\n",
       "  21.38128449599841,\n",
       "  18.88657198196915,\n",
       "  19.79781790732165,\n",
       "  22.44144949430811,\n",
       "  24.035601324956733,\n",
       "  16.716182596448036],\n",
       " [0.9589147423089447,\n",
       "  0.9608469319835847,\n",
       "  0.9345921082092712,\n",
       "  0.9336331698432766,\n",
       "  0.8858472799824806,\n",
       "  0.8727623183681171,\n",
       "  0.877694902748018,\n",
       "  0.8384245002604216,\n",
       "  0.8351286340287088,\n",
       "  0.8672033443352529,\n",
       "  0.9074448431858941,\n",
       "  0.9589305063008853,\n",
       "  0.9691642841659984,\n",
       "  0.9843050997293793,\n",
       "  0.9573330644090576,\n",
       "  0.8855087666838445,\n",
       "  0.8547951862609696,\n",
       "  0.8250766013477897,\n",
       "  0.8287966229246747,\n",
       "  0.8265503915611745,\n",
       "  0.8482391232376296,\n",
       "  0.867994958706513,\n",
       "  0.8901093393175473,\n",
       "  0.9275904572451131],\n",
       " [13.131439843765257,\n",
       "  13.097032647024811,\n",
       "  14.712473050868185,\n",
       "  14.753275665635446,\n",
       "  18.472929222308633,\n",
       "  15.800435079270695,\n",
       "  17.72024191391466,\n",
       "  20.49495875064336,\n",
       "  19.365253982937364,\n",
       "  19.900004902729506,\n",
       "  19.555667998666852,\n",
       "  5.862486994376977,\n",
       "  6.450868159850827,\n",
       "  3.012548487111167,\n",
       "  8.082307865779843,\n",
       "  19.57244967604167,\n",
       "  19.07123761549488,\n",
       "  23.24039765201225,\n",
       "  20.28143613586061,\n",
       "  17.84312406748979,\n",
       "  18.173114586803322,\n",
       "  21.196032806283323,\n",
       "  21.812498899441344,\n",
       "  14.603707304185615],\n",
       " 0.3464952554490607)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin_trainer.test_new(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd634845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test (loss=0.42856): 100%|█████████████████████████████████████████████████████████████| 59/59 [12:13<00:00, 12.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.8916841495697062,\n",
       "  0.8402921569976776,\n",
       "  0.8299484132043737,\n",
       "  0.7780722234195039,\n",
       "  0.7444242679494906,\n",
       "  0.7491268416524595,\n",
       "  0.7974582916865116,\n",
       "  0.732550762257316,\n",
       "  0.7538079907952666,\n",
       "  0.7982335572572347,\n",
       "  0.8314457476529272,\n",
       "  0.7783790644840728,\n",
       "  0.9029091289481793,\n",
       "  0.9147929507631168,\n",
       "  0.8803205826082521,\n",
       "  0.8112027163710938,\n",
       "  0.7039527853086719,\n",
       "  0.7051463845123552,\n",
       "  0.7399483302465315,\n",
       "  0.7806336009046854,\n",
       "  0.7801203800611218,\n",
       "  0.7874311940665506,\n",
       "  0.8034207053669143,\n",
       "  0.801944359747454],\n",
       " [12.729116730720122,\n",
       "  26.664557646721004,\n",
       "  24.613424678234825,\n",
       "  31.25801129376187,\n",
       "  31.45826116410334,\n",
       "  27.688402418810316,\n",
       "  24.982010895873756,\n",
       "  27.562905129049962,\n",
       "  27.258854698401908,\n",
       "  25.208858425429053,\n",
       "  26.307393152356482,\n",
       "  32.56362327907559,\n",
       "  8.951130809488141,\n",
       "  15.605513686874975,\n",
       "  17.722240146712384,\n",
       "  20.87126247090366,\n",
       "  30.714462603824128,\n",
       "  29.489163503193122,\n",
       "  27.59052297382283,\n",
       "  19.488336849972605,\n",
       "  22.15690148576117,\n",
       "  26.37158644984547,\n",
       "  28.06833898828234,\n",
       "  28.26842945047784],\n",
       " [0.9601131930031105,\n",
       "  0.8902556969667387,\n",
       "  0.8880116762790021,\n",
       "  0.8177807208737545,\n",
       "  0.7932064470454435,\n",
       "  0.8085901796622519,\n",
       "  0.835439938733889,\n",
       "  0.7957108482190755,\n",
       "  0.7791991460799187,\n",
       "  0.8401225901780062,\n",
       "  0.8648243712103739,\n",
       "  0.8223227200605054,\n",
       "  0.9643939412377386,\n",
       "  0.9558141543377523,\n",
       "  0.9308609562265243,\n",
       "  0.8753359538897962,\n",
       "  0.7608328550860278,\n",
       "  0.7640180852304315,\n",
       "  0.7695855537504863,\n",
       "  0.8152289448961845,\n",
       "  0.8221138360930479,\n",
       "  0.8330334679248522,\n",
       "  0.8590283841110727,\n",
       "  0.8533937584829834],\n",
       " [12.135060070558941,\n",
       "  27.479689409521264,\n",
       "  23.809375537265016,\n",
       "  31.906893089131543,\n",
       "  32.233770534339456,\n",
       "  28.297434589542725,\n",
       "  24.47176495956923,\n",
       "  26.199815837630798,\n",
       "  27.094177110148195,\n",
       "  23.052029276379635,\n",
       "  26.77874053743128,\n",
       "  34.01161571107292,\n",
       "  7.289560697012004,\n",
       "  15.719823688546086,\n",
       "  16.930671531722243,\n",
       "  19.62606841331765,\n",
       "  30.642781774925904,\n",
       "  29.697022878547696,\n",
       "  27.033393243103337,\n",
       "  17.945637181652422,\n",
       "  20.484778147485002,\n",
       "  25.05441249045864,\n",
       "  26.064853966829016,\n",
       "  28.383360234717458],\n",
       " 0.35826582834124565)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin_trainer.test_new(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3add77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 231, 175, 301]) 1.1332263238728046\n",
      "torch.Size([1, 1, 300, 236, 301]) 1.984722912311554\n",
      "torch.Size([1, 1, 240, 205, 301]) 1.3792142271995544\n",
      "torch.Size([1, 1, 286, 225, 301]) 1.8039112910628319\n",
      "torch.Size([1, 1, 293, 224, 301]) 1.8398493528366089\n",
      "torch.Size([1, 1, 221, 183, 217]) 0.8173408918082714\n",
      "torch.Size([1, 1, 202, 159, 244]) 0.7298581302165985\n",
      "torch.Size([1, 1, 252, 198, 301]) 1.3987250626087189\n",
      "torch.Size([1, 1, 286, 231, 287]) 1.765875332057476\n",
      "torch.Size([1, 1, 251, 218, 247]) 1.258714683353901\n",
      "torch.Size([1, 1, 99, 122, 122]) 0.13723187148571014\n",
      "torch.Size([1, 1, 271, 166, 301]) 1.2610839679837227\n",
      "torch.Size([1, 1, 285, 164, 285]) 1.2406054884195328\n",
      "torch.Size([1, 1, 272, 255, 301]) 1.9443556666374207\n",
      "torch.Size([1, 1, 255, 196, 301]) 1.4010798186063766\n",
      "torch.Size([1, 1, 240, 202, 301]) 1.3590306043624878\n",
      "torch.Size([1, 1, 213, 203, 238]) 0.9584130719304085\n",
      "torch.Size([1, 1, 212, 197, 301]) 1.1707622557878494\n",
      "torch.Size([1, 1, 233, 219, 301]) 1.430430170148611\n",
      "torch.Size([1, 1, 233, 213, 228]) 1.053829863667488\n",
      "torch.Size([1, 1, 241, 241, 265]) 1.4334418810904026\n",
      "torch.Size([1, 1, 233, 233, 301]) 1.5218731947243214\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m      2\u001b[0m     t \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m][:, :, :, :, :\u001b[38;5;241m301\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(t\u001b[38;5;241m.\u001b[39mshape, (t\u001b[38;5;241m.\u001b[39melement_size() \u001b[38;5;241m*\u001b[39m t\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\data\\dataset.py:110\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# dataset[[1, 3, 4]]\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subset(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39mindex)\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\data\\dataset.py:417\u001b[0m, in \u001b[0;36mPersistentDataset._transform\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 417\u001b[0m     pre_random_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cachecheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_transform(pre_random_item)\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\data\\dataset.py:385\u001b[0m, in \u001b[0;36mPersistentDataset._cachecheck\u001b[1;34m(self, item_transformed)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hashfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m hashfile\u001b[38;5;241m.\u001b[39mis_file():  \u001b[38;5;66;03m# cache hit\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 385\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhashfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[0;32m   1110\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1112\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m   1116\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[0;32m   1117\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1118\u001b[0m         _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for d in test_loader:\n",
    "    t = d['image']\n",
    "#     t = d['image'][:, :, :, :, :301]\n",
    "    print(t.shape, (t.element_size() * t.numel() * 25) / (1024 ** 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:1024\"\n",
    "torch.cuda.mem_get_info()[0] / (1024 ** 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f24257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|                                                                                     | 0/59 [00:00<?, ?it/s]None of the inputs have requires_grad=True. Gradients will be None\n",
      "invalid value encountered in double_scalars\n",
      "torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "Test (loss=0.26597):  86%|████████████████████████████████████████████████████▋        | 51/59 [08:48<01:11,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 331, 321, 603]) cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test (loss=0.26597):  86%|████████████████████████████████████████████████████▋        | 51/59 [13:40<02:08, 16.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mswin_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_multi_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Arash\\AnatomySegmentation\\trainer.py:393\u001b[0m, in \u001b[0;36mTrainer.test_multi_device\u001b[1;34m(self, test_loader)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28mprint\u001b[39m(test_inputs\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m#                 test_outputs = sliding_window_inference(test_inputs, (96, 96, 96), num_samples, model, overlap=0.8)\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     test_outputs \u001b[38;5;241m=\u001b[39m \u001b[43msliding_window_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(test_outputs\u001b[38;5;241m.\u001b[39mdetach(), test_labels\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    396\u001b[0m test_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\inferers\\utils.py:190\u001b[0m, in \u001b[0;36msliding_window_inference\u001b[1;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, sigma_scale, padding_mode, cval, sw_device, device, progress, roi_weight_map, process_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m unravel_slice \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    184\u001b[0m     [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win), \u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(slices[idx \u001b[38;5;241m%\u001b[39m num_win])\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m slice_range\n\u001b[0;32m    186\u001b[0m ]\n\u001b[0;32m    187\u001b[0m window_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m    188\u001b[0m     [convert_data_type(inputs[win_slice], torch\u001b[38;5;241m.\u001b[39mTensor)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m win_slice \u001b[38;5;129;01min\u001b[39;00m unravel_slice]\n\u001b[0;32m    189\u001b[0m )\u001b[38;5;241m.\u001b[39mto(sw_device)\n\u001b[1;32m--> 190\u001b[0m seg_prob_out \u001b[38;5;241m=\u001b[39m predictor(window_data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# batched patch segmentation\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# convert seg_prob_out to tuple seg_prob_tuple, this does not allocate new memory.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m seg_prob_tuple: \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\networks\\nets\\swin_unetr.py:311\u001b[0m, in \u001b[0;36mSwinUNETR.forward\u001b[1;34m(self, x_in)\u001b[0m\n\u001b[0;32m    309\u001b[0m dec1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder3(dec2, enc2)\n\u001b[0;32m    310\u001b[0m dec0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder2(dec1, enc1)\n\u001b[1;32m--> 311\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(out)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\networks\\blocks\\unetr_block.py:85\u001b[0m, in \u001b[0;36mUnetrUpBlock.forward\u001b[1;34m(self, inp, skip)\u001b[0m\n\u001b[0;32m     83\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransp_conv(inp)\n\u001b[0;32m     84\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((out, skip), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\monai\\networks\\blocks\\dynunet_block.py:108\u001b[0m, in \u001b[0;36mUnetResBlock.forward\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m    106\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(residual)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm3\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 108\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual\n\u001b[0;32m    110\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(out)\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\nn\\modules\\instancenorm.py:74\u001b[0m, in \u001b[0;36m_InstanceNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_no_batch_dim():\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_no_batch_input(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_instance_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\nn\\modules\\instancenorm.py:34\u001b[0m, in \u001b[0;36m_InstanceNorm._apply_instance_norm\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_instance_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Arash\\Semester2\\DeepLearning\\FinalProject\\venv\\lib\\site-packages\\torch\\nn\\functional.py:2495\u001b[0m, in \u001b[0;36minstance_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_input_stats:\n\u001b[0;32m   2494\u001b[0m     _verify_spatial_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_input_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "swin_trainer.test_multi_device(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443dd3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_trainer.multiple_test(\n",
    "    file_list_test=file_list_test,\n",
    "    task_name=task_name,\n",
    "    val_transforms=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in train_loader:\n",
    "    if t['label'].max() == 0:\n",
    "        print(t['label'].min(), t['label'].max() == 0)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DeepLearningFinalProject)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
